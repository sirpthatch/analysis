{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa810d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cities_df = pd.read_csv('data/uscities.csv')  # from simplemaps\n",
    "race_cities_df= pd.read_csv('data/top_training_cities_80pct.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "348e6c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new york</td>\n",
       "      <td>NY</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "      <td>ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>34.1141</td>\n",
       "      <td>-118.4068</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>41.8375</td>\n",
       "      <td>-87.6866</td>\n",
       "      <td>il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>25.7840</td>\n",
       "      <td>-80.2101</td>\n",
       "      <td>fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>29.7860</td>\n",
       "      <td>-95.3885</td>\n",
       "      <td>tx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city state_id      lat       lng state\n",
       "0     new york       NY  40.6943  -73.9249    ny\n",
       "1  los angeles       CA  34.1141 -118.4068    ca\n",
       "2      chicago       IL  41.8375  -87.6866    il\n",
       "3        miami       FL  25.7840  -80.2101    fl\n",
       "4      houston       TX  29.7860  -95.3885    tx"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df_p = cities_df[['city','state_id','lat','lng']]\n",
    "cities_df_p['city'] = cities_df_p['city'].apply(str.lower)\n",
    "cities_df_p['state'] = cities_df_p['state_id'].apply(str.lower)\n",
    "cities_df_p.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7927a167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>runner_count</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>ca</td>\n",
       "      <td>121020</td>\n",
       "      <td>34.1141</td>\n",
       "      <td>-118.4068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chicago</td>\n",
       "      <td>il</td>\n",
       "      <td>120839</td>\n",
       "      <td>41.8375</td>\n",
       "      <td>-87.6866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new york</td>\n",
       "      <td>ny</td>\n",
       "      <td>96250</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>houston</td>\n",
       "      <td>tx</td>\n",
       "      <td>59373</td>\n",
       "      <td>29.7860</td>\n",
       "      <td>-95.3885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>57024</td>\n",
       "      <td>32.8313</td>\n",
       "      <td>-117.1222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city state  runner_count      lat       lng\n",
       "0  los angeles    ca        121020  34.1141 -118.4068\n",
       "1      chicago    il        120839  41.8375  -87.6866\n",
       "2     new york    ny         96250  40.6943  -73.9249\n",
       "3      houston    tx         59373  29.7860  -95.3885\n",
       "4    san diego    ca         57024  32.8313 -117.1222"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = race_cities_df.merge(cities_df_p[['city', 'state', 'lat', 'lng']], \n",
    "                          left_on=['city', 'state'], \n",
    "                          right_on=['city', 'state'])\n",
    "merged.to_csv('data/mapped_cities.csv', index=False)\n",
    "merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b47ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped: 5934659\n",
      "Unmapped: 691650\n",
      "Coverage:       89.56%\n"
     ]
    }
   ],
   "source": [
    "missing_cities = race_cities_df[~race_cities_df.city.isin(merged.city)]\n",
    "\n",
    "mapped_amount = race_cities_df.runner_count.sum() / (missing_cities.runner_count.sum() + race_cities_df.runner_count.sum())\n",
    "print(f\"Mapped: {race_cities_df.runner_count.sum()}\")\n",
    "print(f\"Unmapped: {missing_cities.runner_count.sum()}\")\n",
    "print(f\"Coverage: {mapped_amount*100:>11.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b45124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def get_historical_weather(lat, lon, start_date, end_date):\n",
    "    \"\"\"Fetch daily weather from Open-Meteo archive API.\"\"\"\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": [\"temperature_2m_max\", \"temperature_2m_min\", \"precipitation_sum\"],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Weather API Error: {response.status_code}\")\n",
    "        print(f\"Message: {response.text}\")\n",
    "        if response.status_code == 429:\n",
    "            print(\"sleeping for 60 seconds...\")\n",
    "            sleep(60)\n",
    "        raise Exception(\"exception querying weather api\")\n",
    "    \n",
    "def fetch_weather_for_cities(df, start_date, end_date, output_path=\"data/weather_data_v2.csv\", save_every=10):\n",
    "    \"\"\"\n",
    "    Fetch weather for all cities, with progress bar and checkpoint saving.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with city, state, lat, lng columns\n",
    "        start_date: Start date string \"YYYY-MM-DD\"\n",
    "        end_date: End date string \"YYYY-MM-DD\"\n",
    "        output_path: Where to save intermediate/final results\n",
    "        save_every: Save checkpoint every N cities\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    \n",
    "    # Load existing results if resuming\n",
    "    if output_path.exists():\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        completed = set(zip(existing_df['city'], existing_df['state']))\n",
    "        weather_records = existing_df.to_dict('records')\n",
    "        print(f\"Resuming: found {len(completed)} cities already processed at {output_path}\")\n",
    "    else:\n",
    "        completed = set()\n",
    "        weather_records = []\n",
    "    \n",
    "    # Filter to only cities we haven't done yet\n",
    "    remaining = df[~df.apply(lambda r: (r['city'], r['state']) in completed, axis=1)]\n",
    "    \n",
    "    if len(remaining) == 0:\n",
    "        print(\"All cities already processed!\")\n",
    "        return pd.read_csv(output_path)\n",
    "    \n",
    "    print(f\"Fetching weather for {len(remaining)} cities...\")\n",
    "    \n",
    "    for i, (idx, row) in enumerate(tqdm(remaining.iterrows(), total=len(remaining), desc=\"Fetching weather\")):\n",
    "        try:\n",
    "            print(f\"Fetching weather for {row[\"city\"]}...\")\n",
    "            data = get_historical_weather(row['lat'], row['lng'], start_date, end_date)\n",
    "            \n",
    "            if data and 'daily' in data:\n",
    "                daily = data['daily']\n",
    "                for j, date in enumerate(daily['time']):\n",
    "                    weather_records.append({\n",
    "                        'city': row['city'],\n",
    "                        'state': row['state'],\n",
    "                        'date': date,\n",
    "                        'temp_max': daily['temperature_2m_max'][j],\n",
    "                        'temp_min': daily['temperature_2m_min'][j],\n",
    "                        'precip': daily['precipitation_sum'][j]\n",
    "                    })\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if (i + 1) % save_every == 0:\n",
    "                print(f\"..incremental save ({len(weather_records)} records) to {output_path}...\")\n",
    "                pd.DataFrame(weather_records).to_csv(output_path, index=False)\n",
    "                \n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error fetching {row['city']}, {row['state']}: {e}\")\n",
    "            #raise e\n",
    "        \n",
    "        sleep(15)\n",
    "    \n",
    "    # Final save\n",
    "    result_df = pd.DataFrame(weather_records)\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {len(result_df)} records to {output_path}\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "    \"latitude\": merged.iloc[0].lat,\n",
    "    \"longitude\": merged.iloc[0].lng,\n",
    "    \"start_date\": \"1999-01-01\",\n",
    "    \"end_date\": \"2026-01-01\",\n",
    "    \"daily\": [\"temperature_2m_max\", \"temperature_2m_min\", \"precipitation_sum\"],\n",
    "    \"temperature_unit\": \"fahrenheit\",\n",
    "    \"timezone\": \"auto\"\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e18ee1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.37401059859706975)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.runner_count.iloc[0:85].sum()/merged.runner_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "zq5lareug6q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming: found 85 cities already processed at data/weather_data_v2.csv\n",
      "Fetching weather for 2532 cities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc328797b7714571a2a8452205da6b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching weather:   0%|          | 0/2532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather for orlando...\n",
      "Weather API Error: 429\n",
      "Message: {\"error\":true,\"reason\":\"Daily API request limit exceeded. Please try again tomorrow.\"}\n",
      "sleeping for 60 seconds...\n",
      "Error fetching orlando, fl: exception querying weather api\n",
      "Fetching weather for baltimore...\n",
      "Weather API Error: 429\n",
      "Message: {\"error\":true,\"reason\":\"Daily API request limit exceeded. Please try again tomorrow.\"}\n",
      "sleeping for 60 seconds...\n",
      "Error fetching baltimore, md: exception querying weather api\n",
      "Fetching weather for miami...\n",
      "Weather API Error: 429\n",
      "Message: {\"reason\":\"Daily API request limit exceeded. Please try again tomorrow.\",\"error\":true}\n",
      "sleeping for 60 seconds...\n",
      "Error fetching miami, fl: exception querying weather api\n",
      "Fetching weather for richmond...\n",
      "Weather API Error: 429\n",
      "Message: {\"error\":true,\"reason\":\"Daily API request limit exceeded. Please try again tomorrow.\"}\n",
      "sleeping for 60 seconds...\n",
      "Error fetching richmond, va: exception querying weather api\n",
      "Fetching weather for san antonio...\n",
      "Weather API Error: 429\n",
      "Message: {\"error\":true,\"reason\":\"Daily API request limit exceeded. Please try again tomorrow.\"}\n",
      "sleeping for 60 seconds...\n",
      "Error fetching san antonio, tx: exception querying weather api\n",
      "Fetching weather for indianapolis...\n",
      "Weather API Error: 429\n",
      "Message: {\"error\":true,\"reason\":\"Daily API request limit exceeded. Please try again tomorrow.\"}\n",
      "sleeping for 60 seconds...\n",
      "Error fetching indianapolis, in: exception querying weather api\n",
      "Fetching weather for las vegas...\n",
      "Weather API Error: 429\n",
      "Message: {\"error\":true,\"reason\":\"Daily API request limit exceeded. Please try again tomorrow.\"}\n",
      "sleeping for 60 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m merged = merged.sort_values(by=\u001b[33m\"\u001b[39m\u001b[33mrunner_count\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# start with the most common cities\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Fetch weather data (can be interrupted and resumed)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m weather_df = \u001b[43mfetch_weather_for_cities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmerged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1999-01-01\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2026-01-01\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/weather_data_v2.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m weather_df.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mfetch_weather_for_cities\u001b[39m\u001b[34m(df, start_date, end_date, output_path, save_every)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching weather for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m\"\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     data = \u001b[43mget_historical_weather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlng\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdaily\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m     68\u001b[39m         daily = data[\u001b[33m'\u001b[39m\u001b[33mdaily\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mget_historical_weather\u001b[39m\u001b[34m(lat, lon, start_date, end_date)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33msleeping for 60 seconds...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mexception querying weather api\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "merged = merged.sort_values(by=\"runner_count\", ascending=False) # start with the most common cities\n",
    "# Fetch weather data (can be interrupted and resumed)\n",
    "weather_df = fetch_weather_for_cities(\n",
    "    merged, \n",
    "    \"1999-01-01\", \n",
    "    \"2026-01-01\",\n",
    "    output_path=\"data/weather_data_v2.csv\",\n",
    "    save_every=1\n",
    ")\n",
    "weather_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
